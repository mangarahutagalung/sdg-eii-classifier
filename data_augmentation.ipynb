{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find if you can use GPU for augment data\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "## cuda installation path: C:\\Users\\Admin\\AppData\\Local\\Temp\\CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import all libraries\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# this is the main library that we use to augment our text data\n",
    "import nlpaug.augmenter.word.context_word_embs as aug\n",
    "\n",
    "augmenter = aug.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data to environment\n",
    "# this data is generated from the scraper.ipynb file\n",
    "all_data_original = pd.read_pickle('all_data_transformed_simplified.pkl')\n",
    "all_data_original.rename(columns=lambda x: x.strip(),inplace=True)\n",
    "all_data_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to augment texts data:\n",
    "1. Split the data into train and test/validation\n",
    "    * We need to split the data before augmenting them. This ensures that the model used during the test/validation stage has not yet seen the data.\n",
    "    * We split the data to train versus test by 80:20 for both class 0 and class 1\n",
    "2. We then augment ONLY the class 1 to match the quantity of class 0 data\n",
    "    * We augment the data up to 1,500\n",
    "    * Except GoodHealth. We only augment 700 new data for GoodHealth. This is because GoodHealth already has a high number of actual class 1 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 654/1500 [01:27<01:53,  7.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\UPenn other stuff\\The Environmental Innovations Initiative\\SDG\\downloads\\data analysis\\div_plus_p_07292022\\web_scraper_data_augmentation.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# NoPoverty_df.drop(NoPoverty_df.columns[[0]], axis=1, inplace=True)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m NoPoverty_train, NoPoverty_test \u001b[39m=\u001b[39m train_test_split(NoPoverty_df, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                                                    random_state\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m                                                    test_size\u001b[39m=\u001b[39m\u001b[39m0.20\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                                                    stratify\u001b[39m=\u001b[39mNoPoverty_df[\u001b[39m'\u001b[39m\u001b[39mNoPoverty\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m NoPoverty__train_aug \u001b[39m=\u001b[39m augmentNoPoverty(NoPoverty_train, augmenter, samples\u001b[39m=\u001b[39;49m\u001b[39m1500\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m NoPoverty__train_aug\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\UPenn other stuff\\The Environmental Innovations Initiative\\SDG\\downloads\\data analysis\\div_plus_p_07292022\\web_scraper_data_augmentation.ipynb Cell 16\u001b[0m in \u001b[0;36maugmentNoPoverty\u001b[1;34m(df, augmenter, repetitions, samples)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(positive_df), samples)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# generating 'n_samples' augmented texts\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(repetitions):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         augmented_text \u001b[39m=\u001b[39m augmenter\u001b[39m.\u001b[39;49maugment(positive_df[\u001b[39m'\u001b[39;49m\u001b[39mtranscripts_simplified\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mloc[i])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         augmented_texts\u001b[39m.\u001b[39mappend(augmented_text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mNoPoverty\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtranscripts_simplified\u001b[39m\u001b[39m'\u001b[39m: augmented_texts\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/UPenn%20other%20stuff/The%20Environmental%20Innovations%20Initiative/SDG/downloads/data%20analysis/div_plus_p_07292022/web_scraper_data_augmentation.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nlpaug\\base_augmenter.py:98\u001b[0m, in \u001b[0;36mAugmenter.augment\u001b[1;34m(self, data, n, num_thread)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mAbstSummAug\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBackTranslationAug\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mContextualWordEmbsAug\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mContextualWordEmbsForSentenceAug\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     97\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(aug_num):\n\u001b[1;32m---> 98\u001b[0m         result \u001b[39m=\u001b[39m action_fx(clean_data)\n\u001b[0;32m     99\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    100\u001b[0m             augmented_results\u001b[39m.\u001b[39mextend(result)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nlpaug\\augmenter\\word\\context_word_embs.py:306\u001b[0m, in \u001b[0;36mContextualWordEmbsAug.insert\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(masked_texts):\n\u001b[0;32m    304\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(masked_texts, target_words\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, n\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m    308\u001b[0m \u001b[39m# Update doc\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39mfor\u001b[39;00m aug_input_pos, output, masked_text \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(aug_input_poses, outputs, masked_texts):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nlpaug\\model\\lang_models\\bert.py:82\u001b[0m, in \u001b[0;36mBert.predict\u001b[1;34m(self, texts, target_words, n)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39m# Prepare inputs\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(texts), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size):\n\u001b[1;32m---> 82\u001b[0m     token_inputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mencode(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts[i:i\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size]]\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m target_words \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m         target_words \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(token_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nlpaug\\model\\lang_models\\bert.py:82\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39m# Prepare inputs\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(texts), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size):\n\u001b[1;32m---> 82\u001b[0m     token_inputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mencode(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts[i:i\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size]]\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m target_words \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m         target_words \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(token_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2278\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m   2241\u001b[0m \u001b[39m@add_end_docstrings\u001b[39m(\n\u001b[0;32m   2242\u001b[0m     ENCODE_KWARGS_DOCSTRING,\n\u001b[0;32m   2243\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2261\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   2262\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mint\u001b[39m]:\n\u001b[0;32m   2263\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m \u001b[39m    Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\u001b[39;00m\n\u001b[0;32m   2265\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2276\u001b[0m \u001b[39m            method).\u001b[39;00m\n\u001b[0;32m   2277\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2278\u001b[0m     encoded_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[0;32m   2279\u001b[0m         text,\n\u001b[0;32m   2280\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   2281\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2282\u001b[0m         padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2283\u001b[0m         truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   2284\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   2285\u001b[0m         stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   2286\u001b[0m         return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2287\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2288\u001b[0m     )\n\u001b[0;32m   2290\u001b[0m     \u001b[39mreturn\u001b[39;00m encoded_inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2610\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2600\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2601\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2602\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2603\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2607\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2608\u001b[0m )\n\u001b[1;32m-> 2610\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_plus(\n\u001b[0;32m   2611\u001b[0m     text\u001b[39m=\u001b[39mtext,\n\u001b[0;32m   2612\u001b[0m     text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   2613\u001b[0m     add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2614\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m   2615\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   2616\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   2617\u001b[0m     stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   2618\u001b[0m     is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2619\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2620\u001b[0m     return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2621\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2622\u001b[0m     return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2623\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2624\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2625\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2626\u001b[0m     return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m   2627\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m   2628\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2629\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:499\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode_plus\u001b[39m(\n\u001b[0;32m    477\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    478\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    496\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BatchEncoding:\n\u001b[0;32m    498\u001b[0m     batched_input \u001b[39m=\u001b[39m [(text, text_pair)] \u001b[39mif\u001b[39;00m text_pair \u001b[39melse\u001b[39;00m [text]\n\u001b[1;32m--> 499\u001b[0m     batched_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m    500\u001b[0m         batched_input,\n\u001b[0;32m    501\u001b[0m         is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m    502\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m    503\u001b[0m         padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m    504\u001b[0m         truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[0;32m    505\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m    506\u001b[0m         stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m    507\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    508\u001b[0m         return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m    509\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    510\u001b[0m         return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    511\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    512\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    513\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    514\u001b[0m         return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m    515\u001b[0m         verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m    516\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    517\u001b[0m     )\n\u001b[0;32m    519\u001b[0m     \u001b[39m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[0;32m    520\u001b[0m     \u001b[39m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[0;32m    521\u001b[0m     \u001b[39mif\u001b[39;00m return_tensors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:426\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_truncation_and_padding(\n\u001b[0;32m    419\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m    420\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    424\u001b[0m )\n\u001b[1;32m--> 426\u001b[0m encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenizer\u001b[39m.\u001b[39;49mencode_batch(\n\u001b[0;32m    427\u001b[0m     batch_text_or_text_pairs,\n\u001b[0;32m    428\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m    429\u001b[0m     is_pretokenized\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m    430\u001b[0m )\n\u001b[0;32m    432\u001b[0m \u001b[39m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39m#                       List[EncodingFast]\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[39m#                    ]\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[39m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    438\u001b[0m tokens_and_encodings \u001b[39m=\u001b[39m [\n\u001b[0;32m    439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_encoding(\n\u001b[0;32m    440\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[39mfor\u001b[39;00m encoding \u001b[39min\u001b[39;00m encodings\n\u001b[0;32m    450\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for NoPoverty\n",
    "def augmentNoPoverty(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['NoPoverty'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'NoPoverty': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "\n",
    "# split the data into train vs test\n",
    "NoPoverty_df = all_data_original.drop(['ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "NoPoverty_train, NoPoverty_test = train_test_split(NoPoverty_df, \n",
    "                                                   random_state=10, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=NoPoverty_df['NoPoverty'])\n",
    "\n",
    "# run the data augmenter \n",
    "NoPoverty__train_aug = augmentNoPoverty(NoPoverty_train, augmenter, samples=1500)\n",
    "NoPoverty__train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    394\n",
      "1      5\n",
      "Name: NoPoverty, dtype: int64\n",
      "0    1574\n",
      "1    1520\n",
      "Name: NoPoverty, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# save the augmented data into train file, and the test data into test file\n",
    "NoPoverty__train_aug.to_csv('NoPoverty_train_aug_simplified.csv')\n",
    "NoPoverty__train_aug.to_pickle('NoPoverty_train_aug_simplified.pkl')\n",
    "NoPoverty_test.to_csv('NoPoverty_test_simplified.csv')\n",
    "NoPoverty_test.to_pickle('NoPoverty_test_simplified.pkl')\n",
    "print(NoPoverty_test['NoPoverty'].value_counts())\n",
    "print(NoPoverty__train_aug['NoPoverty'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [04:47<00:00,  5.21it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\405345658.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZeroHunger</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>0</td>\n",
       "      <td>gender gender heritage heritage voice land cul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>1</td>\n",
       "      <td>[pay medical medical healthcare pay medical me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>0</td>\n",
       "      <td>pay medical medical healthcare pay medical med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>0</td>\n",
       "      <td>decision secondary decision health decision co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>education natural primary work work cultural n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ZeroHunger                             transcripts_simplified\n",
       "1434           0  gender gender heritage heritage voice land cul...\n",
       "1822           1  [pay medical medical healthcare pay medical me...\n",
       "1088           0  pay medical medical healthcare pay medical med...\n",
       "1344           0  decision secondary decision health decision co...\n",
       "474            0  education natural primary work work cultural n..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for ZeroHunger\n",
    "def augmentZeroHunger(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['ZeroHunger'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'ZeroHunger': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "ZeroHunger_df = all_data_original.drop(['NoPoverty','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "ZeroHunger_train, ZeroHunger_test = train_test_split(ZeroHunger_df, \n",
    "                                                   random_state=11, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=ZeroHunger_df['ZeroHunger'])\n",
    "ZeroHunger_train_aug = augmentZeroHunger(ZeroHunger_train, augmenter, samples=1500)\n",
    "ZeroHunger_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    392\n",
      "1      7\n",
      "Name: ZeroHunger, dtype: int64\n",
      "0    1565\n",
      "1    1529\n",
      "Name: ZeroHunger, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ZeroHunger_train_aug.to_csv('ZeroHunger_train_aug_simplified.csv')\n",
    "ZeroHunger_train_aug.to_pickle('ZeroHunger_train_aug_simplified.pkl')\n",
    "ZeroHunger_test.to_csv('ZeroHunger_test_simplified.csv')\n",
    "ZeroHunger_test.to_pickle('ZeroHunger_test_simplified.pkl')\n",
    "print(ZeroHunger_test['ZeroHunger'].value_counts())\n",
    "print(ZeroHunger_train_aug['ZeroHunger'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [02:06<00:00,  5.52it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\3181179607.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GoodHealth</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0</td>\n",
       "      <td>entrepreneurship entrepreneurship leadership e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1</td>\n",
       "      <td>[resource farm covid covid medicine education ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0</td>\n",
       "      <td>industry autonomy economic network security so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GoodHealth                             transcripts_simplified\n",
       "1248           1  coronavirus covid resource resource coronaviru...\n",
       "178            1  coronavirus covid resource resource coronaviru...\n",
       "832            0  entrepreneurship entrepreneurship leadership e...\n",
       "1725           1  [resource farm covid covid medicine education ...\n",
       "617            0  industry autonomy economic network security so..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for GoodHealth\n",
    "def augmentGoodHealth(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['GoodHealth'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'GoodHealth': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "GoodHealth_df = all_data_original.drop(['NoPoverty','ZeroHunger','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "GoodHealth_train, GoodHealth_test = train_test_split(GoodHealth_df, \n",
    "                                                   random_state=12, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=GoodHealth_df['GoodHealth'])\n",
    "\n",
    "# notice we uses sample=700 instead of 1500 for GoodHealth here\n",
    "GoodHealth_train_aug = augmentGoodHealth(GoodHealth_train, augmenter, samples=700)\n",
    "GoodHealth_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    212\n",
      "1    187\n",
      "Name: GoodHealth, dtype: int64\n",
      "1    1445\n",
      "0     849\n",
      "Name: GoodHealth, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "GoodHealth_train_aug.to_csv('GoodHealth_train_aug_simplified.csv')\n",
    "GoodHealth_train_aug.to_pickle('GoodHealth_train_aug_simplified.pkl')\n",
    "GoodHealth_test.to_csv('GoodHealth_test_simplified.csv')\n",
    "GoodHealth_test.to_pickle('GoodHealth_test_simplified.pkl')\n",
    "print(GoodHealth_test['GoodHealth'].value_counts())\n",
    "print(GoodHealth_train_aug['GoodHealth'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [03:55<00:00,  6.37it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\2820499970.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QualityEducation</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>0</td>\n",
       "      <td>health health health health health health heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>0</td>\n",
       "      <td>health health health health health health heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>1</td>\n",
       "      <td>[law applied law law law education skill educa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      QualityEducation                             transcripts_simplified\n",
       "1040                 0  health health health health health health heal...\n",
       "1054                 0  coronavirus covid resource resource coronaviru...\n",
       "1145                 0  coronavirus covid resource resource coronaviru...\n",
       "1305                 0  health health health health health health heal...\n",
       "2149                 1  [law applied law law law education skill educa..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for QualityEducation\n",
    "def augmentQualityEducation(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['QualityEducation'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'QualityEducation': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "QualityEducation_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "QualityEducation_train, QualityEducation_test = train_test_split(QualityEducation_df, \n",
    "                                                   random_state=13, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=QualityEducation_df['QualityEducation'])\n",
    "QualityEducation_train_aug = augmentQualityEducation(QualityEducation_train, augmenter, samples=1500)\n",
    "QualityEducation_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    370\n",
      "1     29\n",
      "Name: QualityEducation, dtype: int64\n",
      "1    1615\n",
      "0    1479\n",
      "Name: QualityEducation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "QualityEducation_train_aug.to_csv('QualityEducation_train_aug_simplified.csv')\n",
    "QualityEducation_train_aug.to_pickle('QualityEducation_train_aug_simplified.pkl')\n",
    "QualityEducation_test.to_csv('QualityEducation_test_simplified.csv')\n",
    "QualityEducation_test.to_pickle('QualityEducation_test_simplified.pkl')\n",
    "print(QualityEducation_test['QualityEducation'].value_counts())\n",
    "print(QualityEducation_train_aug['QualityEducation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [04:29<00:00,  5.56it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\1715069148.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GenderEquality</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>0</td>\n",
       "      <td>work education work education medicine medicin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0</td>\n",
       "      <td>financial leadership education inclusion resou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0</td>\n",
       "      <td>city resource primary city medicine medicine p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>0</td>\n",
       "      <td>medicine education medical medical medicine ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0</td>\n",
       "      <td>resource farm covid covid medicine medicine ed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GenderEquality                             transcripts_simplified\n",
       "1489               0  work education work education medicine medicin...\n",
       "442                0  financial leadership education inclusion resou...\n",
       "772                0  city resource primary city medicine medicine p...\n",
       "1168               0  medicine education medical medical medicine ch...\n",
       "636                0  resource farm covid covid medicine medicine ed..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for GenderEquality\n",
    "def augmentGenderEquality(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['GenderEquality'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'GenderEquality': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "GenderEquality_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "GenderEquality_train, GenderEquality_test = train_test_split(GenderEquality_df, \n",
    "                                                   random_state=14, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=GenderEquality_df['GenderEquality'])\n",
    "GenderEquality_train_aug = augmentGenderEquality(GenderEquality_train, augmenter, samples=1500)\n",
    "GenderEquality_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    378\n",
      "1     21\n",
      "Name: GenderEquality, dtype: int64\n",
      "1    1582\n",
      "0    1512\n",
      "Name: GenderEquality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "GenderEquality_train_aug.to_csv('GenderEquality_train_aug_simplified.csv')\n",
    "GenderEquality_train_aug.to_pickle('GenderEquality_train_aug_simplified.pkl')\n",
    "GenderEquality_test.to_csv('GenderEquality_test_simplified.csv')\n",
    "GenderEquality_test.to_pickle('GenderEquality_test_simplified.pkl')\n",
    "print(GenderEquality_test['GenderEquality'].value_counts())\n",
    "print(GenderEquality_train_aug['GenderEquality'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [02:14<00:00, 11.13it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\1491485569.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanWater</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>1</td>\n",
       "      <td>[resource work work work physical chemical phy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>1</td>\n",
       "      <td>[voice building education education energy con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1</td>\n",
       "      <td>[resource work work work physical chemical phy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>1</td>\n",
       "      <td>[covid justice city preservation urban energy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>work leadership welfare work partnership welfa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CleanWater                             transcripts_simplified\n",
       "1947           1  [resource work work work physical chemical phy...\n",
       "2922           1  [voice building education education energy con...\n",
       "1677           1  [resource work work work physical chemical phy...\n",
       "2629           1  [covid justice city preservation urban energy ...\n",
       "477            0  work leadership welfare work partnership welfa..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for CleanWater\n",
    "def augmentCleanWater(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['CleanWater'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'CleanWater': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "CleanWater_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "CleanWater_train, CleanWater_test = train_test_split(CleanWater_df, \n",
    "                                                   random_state=15, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=CleanWater_df['CleanWater'])\n",
    "CleanWater_train_aug = augmentCleanWater(CleanWater_train, augmenter, samples=1500)\n",
    "CleanWater_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    396\n",
      "1      3\n",
      "Name: CleanWater, dtype: int64\n",
      "0    1584\n",
      "1    1510\n",
      "Name: CleanWater, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "CleanWater_train_aug.to_csv('CleanWater_train_aug_simplified.csv')\n",
    "CleanWater_train_aug.to_pickle('CleanWater_train_aug_simplified.pkl')\n",
    "CleanWater_test.to_csv('CleanWater_test_simplified.csv')\n",
    "CleanWater_test.to_pickle('CleanWater_test_simplified.pkl')\n",
    "print(CleanWater_test['CleanWater'].value_counts())\n",
    "print(CleanWater_train_aug['CleanWater'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [02:38<00:00,  9.48it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\2803562907.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AffordableCleanEnergy</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>1</td>\n",
       "      <td>[covid justice city preservation urban energy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>1</td>\n",
       "      <td>[building building building labor ecology ener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>1</td>\n",
       "      <td>[covid justice city preservation urban energy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>1</td>\n",
       "      <td>[law law law law education skill education law...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AffordableCleanEnergy                             transcripts_simplified\n",
       "2461                      1  [covid justice city preservation urban energy ...\n",
       "2648                      1  [building building building labor ecology ener...\n",
       "351                       0  coronavirus covid resource resource coronaviru...\n",
       "3019                      1  [covid justice city preservation urban energy ...\n",
       "1860                      1  [law law law law education skill education law..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for AffordableCleanEnergy\n",
    "def augmentAffordableCleanEnergy(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['AffordableCleanEnergy'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'AffordableCleanEnergy': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "AffordableCleanEnergy_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "AffordableCleanEnergy_train, AffordableCleanEnergy_test = train_test_split(AffordableCleanEnergy_df, \n",
    "                                                   random_state=17, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=AffordableCleanEnergy_df['AffordableCleanEnergy'])\n",
    "AffordableCleanEnergy_train_aug = augmentAffordableCleanEnergy(AffordableCleanEnergy_train, augmenter, samples=1500)\n",
    "AffordableCleanEnergy_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    392\n",
      "1      7\n",
      "Name: AffordableCleanEnergy, dtype: int64\n",
      "0    1568\n",
      "1    1526\n",
      "Name: AffordableCleanEnergy, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "AffordableCleanEnergy_train_aug.to_csv('AffordableCleanEnergy_train_aug_simplified.csv')\n",
    "AffordableCleanEnergy_train_aug.to_pickle('AffordableCleanEnergy_train_aug_simplified.pkl')\n",
    "AffordableCleanEnergy_test.to_csv('AffordableCleanEnergy_test_simplified.csv')\n",
    "AffordableCleanEnergy_test.to_pickle('AffordableCleanEnergy_test_simplified.pkl')\n",
    "print(AffordableCleanEnergy_test['AffordableCleanEnergy'].value_counts())\n",
    "print(AffordableCleanEnergy_train_aug['AffordableCleanEnergy'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [03:21<00:00,  7.44it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\1995978266.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecentWork</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>1</td>\n",
       "      <td>[secondary job job resource job justice health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>1</td>\n",
       "      <td>[education education risk educational educatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>1</td>\n",
       "      <td>[youth entrepreneurship entrepreneurship job p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>0</td>\n",
       "      <td>medicine medicine medicine medicine medicine m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DecentWork                             transcripts_simplified\n",
       "379            0  coronavirus covid resource resource coronaviru...\n",
       "1950           1  [secondary job job resource job justice health...\n",
       "3052           1  [education education risk educational educatio...\n",
       "2307           1  [youth entrepreneurship entrepreneurship job p...\n",
       "848            0  medicine medicine medicine medicine medicine m..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for DecentWork\n",
    "def augmentDecentWork(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['DecentWork'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'DecentWork': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "DecentWork_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "DecentWork_train, DecentWork_test = train_test_split(DecentWork_df, \n",
    "                                                   random_state=18, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=DecentWork_df['DecentWork'])\n",
    "DecentWork_train_aug = augmentDecentWork(DecentWork_train, augmenter, samples=1500)\n",
    "DecentWork_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    374\n",
      "1     25\n",
      "Name: DecentWork, dtype: int64\n",
      "1    1598\n",
      "0    1496\n",
      "Name: DecentWork, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DecentWork_train_aug.to_csv('DecentWork_train_aug_simplified.csv')\n",
    "DecentWork_train_aug.to_pickle('DecentWork_train_aug_simplified.pkl')\n",
    "DecentWork_test.to_csv('DecentWork_test_simplified.csv')\n",
    "DecentWork_test.to_pickle('DecentWork_test_simplified.pkl')\n",
    "print(DecentWork_test['DecentWork'].value_counts())\n",
    "print(DecentWork_train_aug['DecentWork'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [04:10<00:00,  6.00it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\2048787344.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IndustryInnovation</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>1</td>\n",
       "      <td>[secondary network internet access network acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>1</td>\n",
       "      <td>[work work building work hiv violence hiv crim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0</td>\n",
       "      <td>resource farm covid covid medicine medicine me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>1</td>\n",
       "      <td>[education work leader entrepreneurship enterp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IndustryInnovation                             transcripts_simplified\n",
       "644                    0  coronavirus covid resource resource coronaviru...\n",
       "2545                   1  [secondary network internet access network acc...\n",
       "1669                   1  [work work building work hiv violence hiv crim...\n",
       "775                    0  resource farm covid covid medicine medicine me...\n",
       "2138                   1  [education work leader entrepreneurship enterp..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for IndustryInnovation\n",
    "def augmentIndustryInnovation(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['IndustryInnovation'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'IndustryInnovation': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "IndustryInnovation_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "IndustryInnovation_train, IndustryInnovation_test = train_test_split(IndustryInnovation_df, \n",
    "                                                   random_state=19, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=IndustryInnovation_df['IndustryInnovation'])\n",
    "IndustryInnovation_train_aug = augmentIndustryInnovation(IndustryInnovation_train, augmenter, samples=1500)\n",
    "IndustryInnovation_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    355\n",
      "1     44\n",
      "Name: IndustryInnovation, dtype: int64\n",
      "1    1676\n",
      "0    1418\n",
      "Name: IndustryInnovation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "IndustryInnovation_train_aug.to_csv('IndustryInnovation_train_aug_simplified.csv')\n",
    "IndustryInnovation_train_aug.to_pickle('IndustryInnovation_train_aug_simplified.pkl')\n",
    "IndustryInnovation_test.to_csv('IndustryInnovation_test_simplified.csv')\n",
    "IndustryInnovation_test.to_pickle('IndustryInnovation_test_simplified.pkl')\n",
    "print(IndustryInnovation_test['IndustryInnovation'].value_counts())\n",
    "print(IndustryInnovation_train_aug['IndustryInnovation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [03:57<00:00,  6.30it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\611021162.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReduceInequality</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>1</td>\n",
       "      <td>[covid justice city preservation urban energy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>1</td>\n",
       "      <td>[entrepreneurship network labor work work ineq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>1</td>\n",
       "      <td>[crisis asset abuse asset abuse asset losses a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0</td>\n",
       "      <td>chemical chemical education young chemical nat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ReduceInequality                             transcripts_simplified\n",
       "1951                 1  [covid justice city preservation urban energy ...\n",
       "637                  0  coronavirus covid resource resource coronaviru...\n",
       "2341                 1  [entrepreneurship network labor work work ineq...\n",
       "2350                 1  [crisis asset abuse asset abuse asset losses a...\n",
       "214                  0  chemical chemical education young chemical nat..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for ReduceInequality\n",
    "def augmentReduceInequality(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['ReduceInequality'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'ReduceInequality': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "ReduceInequality_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "ReduceInequality_train, ReduceInequality_test = train_test_split(ReduceInequality_df, \n",
    "                                                   random_state=20, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=ReduceInequality_df['ReduceInequality'])\n",
    "ReduceInequality_train_aug = augmentReduceInequality(ReduceInequality_train, augmenter, samples=1500)\n",
    "ReduceInequality_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    353\n",
      "1     46\n",
      "Name: ReduceInequality, dtype: int64\n",
      "1    1682\n",
      "0    1412\n",
      "Name: ReduceInequality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ReduceInequality_train_aug.to_csv('ReduceInequality_train_aug_simplified.csv')\n",
    "ReduceInequality_train_aug.to_pickle('ReduceInequality_train_aug_simplified.pkl')\n",
    "ReduceInequality_test.to_csv('ReduceInequality_test_simplified.csv')\n",
    "ReduceInequality_test.to_pickle('ReduceInequality_test_simplified.pkl')\n",
    "print(ReduceInequality_test['ReduceInequality'].value_counts())\n",
    "print(ReduceInequality_train_aug['ReduceInequality'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [03:34<00:00,  6.99it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\3703833160.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SustainableCities</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>1</td>\n",
       "      <td>[covid justice city preservation urban energy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>0</td>\n",
       "      <td>physical education energy resource physical ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>1</td>\n",
       "      <td>[education financial financial resource covid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>1</td>\n",
       "      <td>[education financial financial resource covid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>1</td>\n",
       "      <td>[education city urban credit network commodity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SustainableCities                             transcripts_simplified\n",
       "2612                  1  [covid justice city preservation urban energy ...\n",
       "1402                  0  physical education energy resource physical ed...\n",
       "2935                  1  [education financial financial resource covid ...\n",
       "2298                  1  [education financial financial resource covid ...\n",
       "2597                  1  [education city urban credit network commodity..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for SustainableCities\n",
    "def augmentSustainableCities(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['SustainableCities'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'SustainableCities': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "SustainableCities_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "SustainableCities_train, SustainableCities_test = train_test_split(SustainableCities_df, \n",
    "                                                   random_state=21, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=SustainableCities_df['SustainableCities'])\n",
    "SustainableCities_train_aug = augmentSustainableCities(SustainableCities_train, augmenter, samples=1500)\n",
    "SustainableCities_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    387\n",
      "1     12\n",
      "Name: SustainableCities, dtype: int64\n",
      "1    1549\n",
      "0    1545\n",
      "Name: SustainableCities, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "SustainableCities_train_aug.to_csv('SustainableCities_train_aug_simplified.csv')\n",
    "SustainableCities_train_aug.to_pickle('SustainableCities_train_aug_simplified.pkl')\n",
    "SustainableCities_test.to_csv('SustainableCities_test_simplified.csv')\n",
    "SustainableCities_test.to_pickle('SustainableCities_test_simplified.pkl')\n",
    "print(SustainableCities_test['SustainableCities'].value_counts())\n",
    "print(SustainableCities_train_aug['SustainableCities'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [04:03<00:00,  6.16it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\2395703973.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponsibleConsumptionProduction</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>1</td>\n",
       "      <td>[abuse abuse abuse abusive abuse use abuse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>0</td>\n",
       "      <td>inequality work culture culture culture work i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0</td>\n",
       "      <td>resource education resource resource resource ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>1</td>\n",
       "      <td>[youth decision decision decision financial ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ResponsibleConsumptionProduction  \\\n",
       "1940                                 1   \n",
       "726                                  0   \n",
       "711                                  0   \n",
       "3079                                 1   \n",
       "1233                                 0   \n",
       "\n",
       "                                 transcripts_simplified  \n",
       "1940        [abuse abuse abuse abusive abuse use abuse]  \n",
       "726   inequality work culture culture culture work i...  \n",
       "711   resource education resource resource resource ...  \n",
       "3079  [youth decision decision decision financial ed...  \n",
       "1233  coronavirus covid resource resource coronaviru...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for ResponsibleConsumptionProduction\n",
    "def augmentResponsibleConsumptionProduction(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['ResponsibleConsumptionProduction'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'ResponsibleConsumptionProduction': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "ResponsibleConsumptionProduction_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "ResponsibleConsumptionProduction_train, ResponsibleConsumptionProduction_test = train_test_split(ResponsibleConsumptionProduction_df, \n",
    "                                                   random_state=22, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=ResponsibleConsumptionProduction_df['ResponsibleConsumptionProduction'])\n",
    "ResponsibleConsumptionProduction_train_aug = augmentResponsibleConsumptionProduction(ResponsibleConsumptionProduction_train, augmenter, samples=1500)\n",
    "ResponsibleConsumptionProduction_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    391\n",
      "1      8\n",
      "Name: ResponsibleConsumptionProduction, dtype: int64\n",
      "0    1562\n",
      "1    1532\n",
      "Name: ResponsibleConsumptionProduction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ResponsibleConsumptionProduction_train_aug.to_csv('ResponsibleConsumptionProduction_train_aug_simplified.csv')\n",
    "ResponsibleConsumptionProduction_train_aug.to_pickle('ResponsibleConsumptionProduction_train_aug_simplified.pkl')\n",
    "ResponsibleConsumptionProduction_test.to_csv('ResponsibleConsumptionProduction_test_simplified.csv')\n",
    "ResponsibleConsumptionProduction_test.to_pickle('ResponsibleConsumptionProduction_test_simplified.pkl')\n",
    "print(ResponsibleConsumptionProduction_test['ResponsibleConsumptionProduction'].value_counts())\n",
    "print(ResponsibleConsumptionProduction_train_aug['ResponsibleConsumptionProduction'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [03:06<00:00,  8.05it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\3070471563.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClimateAction</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0</td>\n",
       "      <td>resource natural natural civil fundamental lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>medicine education medical medical partnership...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>1</td>\n",
       "      <td>[digital secondary hybrid green building solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0</td>\n",
       "      <td>education financial financial resource covid l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>medicine education medical medical medicine bu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ClimateAction                             transcripts_simplified\n",
       "610               0  resource natural natural civil fundamental lev...\n",
       "298               0  medicine education medical medical partnership...\n",
       "1766              1  [digital secondary hybrid green building solut...\n",
       "587               0  education financial financial resource covid l...\n",
       "170               0  medicine education medical medical medicine bu..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for ClimateAction\n",
    "def augmentClimateAction(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['ClimateAction'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'ClimateAction': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "ClimateAction_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','LifeBelowWater','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "ClimateAction_train, ClimateAction_test = train_test_split(ClimateAction_df, \n",
    "                                                   random_state=23, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=ClimateAction_df['ClimateAction'])\n",
    "ClimateAction_train_aug = augmentClimateAction(ClimateAction_train, augmenter, samples=1500)\n",
    "ClimateAction_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    392\n",
      "1      7\n",
      "Name: ClimateAction, dtype: int64\n",
      "0    1566\n",
      "1    1528\n",
      "Name: ClimateAction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ClimateAction_train_aug.to_csv('ClimateAction_train_aug_simplified.csv')\n",
    "ClimateAction_train_aug.to_pickle('ClimateAction_train_aug_simplified.pkl')\n",
    "ClimateAction_test.to_csv('ClimateAction_test_simplified.csv')\n",
    "ClimateAction_test.to_pickle('ClimateAction_test_simplified.pkl')\n",
    "print(ClimateAction_test['ClimateAction'].value_counts())\n",
    "print(ClimateAction_train_aug['ClimateAction'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [04:35<00:00,  5.45it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\744798981.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LifeBelowWater</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>1</td>\n",
       "      <td>[ecology biodiversity plant genetics education...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0</td>\n",
       "      <td>medicine education medical medical medicine he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>1</td>\n",
       "      <td>[covid justice city preservation urban energy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus covid resource resource coronaviru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LifeBelowWater                             transcripts_simplified\n",
       "686                0  coronavirus covid resource resource coronaviru...\n",
       "2746               1  [ecology biodiversity plant genetics education...\n",
       "215                0  medicine education medical medical medicine he...\n",
       "2520               1  [covid justice city preservation urban energy ...\n",
       "1296               0  coronavirus covid resource resource coronaviru..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for LifeBelowWater\n",
    "def augmentLifeBelowWater(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['LifeBelowWater'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'LifeBelowWater': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "LifeBelowWater_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeonLand','PeaceJustice','Partnerships'], axis=1)\n",
    "LifeBelowWater_train, LifeBelowWater_test = train_test_split(LifeBelowWater_df, \n",
    "                                                   random_state=24, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=LifeBelowWater_df['LifeBelowWater'])\n",
    "LifeBelowWater_train_aug = augmentLifeBelowWater(LifeBelowWater_train, augmenter, samples=1500)\n",
    "LifeBelowWater_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    397\n",
      "1      2\n",
      "Name: LifeBelowWater, dtype: int64\n",
      "0    1587\n",
      "1    1507\n",
      "Name: LifeBelowWater, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "LifeBelowWater_train_aug.to_csv('LifeBelowWater_train_aug_simplified.csv')\n",
    "LifeBelowWater_train_aug.to_pickle('LifeBelowWater_train_aug_simplified.pkl')\n",
    "LifeBelowWater_test.to_csv('LifeBelowWater_test_simplified.csv')\n",
    "LifeBelowWater_test.to_pickle('LifeBelowWater_test_simplified.pkl')\n",
    "print(LifeBelowWater_test['LifeBelowWater'].value_counts())\n",
    "print(LifeBelowWater_train_aug['LifeBelowWater'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [04:22<00:00,  5.72it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\3415420652.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LifeonLand</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>1</td>\n",
       "      <td>[youth decision primary access level biomedica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>covid justice city preservation urban energy u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>1</td>\n",
       "      <td>[resource farm covid covid wildlife wildlife m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "      <td>energy building education resource energy buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>0</td>\n",
       "      <td>law law law law education skill education law ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LifeonLand                             transcripts_simplified\n",
       "2523           1  [youth decision primary access level biomedica...\n",
       "53             0  covid justice city preservation urban energy u...\n",
       "2786           1  [resource farm covid covid wildlife wildlife m...\n",
       "567            0  energy building education resource energy buil...\n",
       "1397           0  law law law law education skill education law ..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for LifeonLand\n",
    "def augmentLifeonLand(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['LifeonLand'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'LifeonLand': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "LifeonLand_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','PeaceJustice','Partnerships'], axis=1)\n",
    "LifeonLand_train, LifeonLand_test = train_test_split(LifeonLand_df, \n",
    "                                                   random_state=25, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=LifeonLand_df['LifeonLand'])\n",
    "LifeonLand_train_aug = augmentLifeonLand(LifeonLand_train, augmenter, samples=1500)\n",
    "LifeonLand_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    395\n",
      "1      4\n",
      "Name: LifeonLand, dtype: int64\n",
      "0    1577\n",
      "1    1517\n",
      "Name: LifeonLand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "LifeonLand_train_aug.to_csv('LifeonLand_train_aug_simplified.csv')\n",
    "LifeonLand_train_aug.to_pickle('LifeonLand_train_aug_simplified.pkl')\n",
    "LifeonLand_test.to_csv('LifeonLand_test_simplified.csv')\n",
    "LifeonLand_test.to_pickle('LifeonLand_test_simplified.pkl')\n",
    "print(LifeonLand_test['LifeonLand'].value_counts())\n",
    "print(LifeonLand_train_aug['LifeonLand'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [04:22<00:00,  5.72it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\3797608397.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeaceJustice</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>1</td>\n",
       "      <td>[population socioeconomic society inequality h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>0</td>\n",
       "      <td>youth credit primary pay work work work work w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1</td>\n",
       "      <td>network inequality network health inequality n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0</td>\n",
       "      <td>work network work network work network work ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>1</td>\n",
       "      <td>[law law law law education skill education law...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PeaceJustice                             transcripts_simplified\n",
       "2420             1  [population socioeconomic society inequality h...\n",
       "923              0  youth credit primary pay work work work work w...\n",
       "207              1  network inequality network health inequality n...\n",
       "609              0  work network work network work network work ne...\n",
       "2215             1  [law law law law education skill education law..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for PeaceJustice\n",
    "def augmentPeaceJustice(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['PeaceJustice'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'PeaceJustice': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "PeaceJustice_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','Partnerships'], axis=1)\n",
    "PeaceJustice_train, PeaceJustice_test = train_test_split(PeaceJustice_df, \n",
    "                                                   random_state=26, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=PeaceJustice_df['PeaceJustice'])\n",
    "PeaceJustice_train_aug = augmentPeaceJustice(PeaceJustice_train, augmenter, samples=1500)\n",
    "PeaceJustice_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    375\n",
      "1     24\n",
      "Name: PeaceJustice, dtype: int64\n",
      "1    1595\n",
      "0    1499\n",
      "Name: PeaceJustice, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "PeaceJustice_train_aug.to_csv('PeaceJustice_train_aug_simplified.csv')\n",
    "PeaceJustice_train_aug.to_pickle('PeaceJustice_train_aug_simplified.pkl')\n",
    "PeaceJustice_test.to_csv('PeaceJustice_test_simplified.csv')\n",
    "PeaceJustice_test.to_pickle('PeaceJustice_test_simplified.pkl')\n",
    "print(PeaceJustice_test['PeaceJustice'].value_counts())\n",
    "print(PeaceJustice_train_aug['PeaceJustice'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [03:48<00:00,  6.56it/s]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\1732233287.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = shuffle(df.append(aug_df).reset_index(drop=True))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partnerships</th>\n",
       "      <th>transcripts_simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>1</td>\n",
       "      <td>[financial leadership education inclusion reso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>1</td>\n",
       "      <td>law law law law education skill education law ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0</td>\n",
       "      <td>youth entrepreneurship entrepreneurship job pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0</td>\n",
       "      <td>resource security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>1</td>\n",
       "      <td>[youth micro job micro job resource primary as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Partnerships                             transcripts_simplified\n",
       "2756             1  [financial leadership education inclusion reso...\n",
       "1084             1  law law law law education skill education law ...\n",
       "947              0  youth entrepreneurship entrepreneurship job pr...\n",
       "744              0                                  resource security\n",
       "2990             1  [youth micro job micro job resource primary as..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom function to augment the data specifically for Partnerships\n",
    "def augmentPartnerships(df, augmenter, repetitions=1, samples=200):\n",
    "    augmented_texts = []\n",
    "    # select only the minority class samples\n",
    "    positive_df = df[df['Partnerships'] == 1].reset_index(drop=True) # removes unecessary index column\n",
    "    for i in tqdm(np.random.randint(0, len(positive_df), samples)):\n",
    "        # generating 'n_samples' augmented texts\n",
    "        for _ in range(repetitions):\n",
    "            augmented_text = augmenter.augment(positive_df['transcripts_simplified'].loc[i])\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    data = {\n",
    "        'Partnerships': 1,\n",
    "        'transcripts_simplified': augmented_texts\n",
    "    }\n",
    "    aug_df = pd.DataFrame(data)\n",
    "    df = shuffle(df.append(aug_df).reset_index(drop=True))\n",
    "    return df\n",
    "\n",
    "Partnerships_df = all_data_original.drop(['NoPoverty','ZeroHunger','GoodHealth','QualityEducation','GenderEquality','CleanWater','AffordableCleanEnergy','DecentWork','IndustryInnovation','ReduceInequality','SustainableCities','ResponsibleConsumptionProduction','ClimateAction','LifeBelowWater','LifeonLand','PeaceJustice'], axis=1)\n",
    "Partnerships_train, Partnerships_test = train_test_split(Partnerships_df, \n",
    "                                                   random_state=26, \n",
    "                                                   test_size=0.20,\n",
    "                                                   stratify=Partnerships_df['Partnerships'])\n",
    "Partnerships_train_aug = augmentPartnerships(Partnerships_train, augmenter, samples=1500)\n",
    "Partnerships_train_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    383\n",
      "1     16\n",
      "Name: Partnerships, dtype: int64\n",
      "1    1564\n",
      "0    1530\n",
      "Name: Partnerships, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Partnerships_train_aug.to_csv('Partnerships_train_aug_simplified.csv')\n",
    "Partnerships_train_aug.to_pickle('Partnerships_train_aug_simplified.pkl')\n",
    "Partnerships_test.to_csv('Partnerships_test_simplified.csv')\n",
    "Partnerships_test.to_pickle('Partnerships_test_simplified.pkl')\n",
    "print(Partnerships_test['Partnerships'].value_counts())\n",
    "print(Partnerships_train_aug['Partnerships'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
